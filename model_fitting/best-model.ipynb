{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Submission - Extra Trees\n",
    "Please check out README.md in our GitHub repo for detailed descriptions: https://github.com/zxyao5148/STAT3612_2023_1A_GroupProject/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries\n",
    "#!pip install scikit-optimize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import io\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from skopt import BayesSearchCV, plots\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load processed datasets\n",
    "# train set\n",
    "train_median = pd.read_csv('../data_processing/train/train_valid_mean_mode.csv')\n",
    "train_latest = pd.read_csv('../data_processing/train/train_valid_latest.csv')\n",
    "train_dispers = pd.read_csv('../data_processing/train/train_valid_entropy_std.csv')\n",
    "train_min = pd.read_csv('../data_processing/train/train_valid_min.csv')\n",
    "train_max = pd.read_csv('../data_processing/train/train_valid_max.csv')\n",
    "train_latest = train_latest.drop(train_latest.columns[0:13], axis=1)\n",
    "train_dispers = train_dispers.drop(train_dispers.columns[0:13], axis=1)\n",
    "train_min = train_min.drop(train_min.columns[0:13], axis=1)\n",
    "train_max = train_max.drop(train_max.columns[0:13], axis=1)\n",
    "train = pd.concat([train_median, train_latest, train_dispers, train_min, train_max], axis=1)\n",
    "\n",
    "# load processed data\n",
    "test_median = pd.read_csv('../data_processing/test/test_mean_mode.csv')\n",
    "test_latest = pd.read_csv('../data_processing/test/test_latest.csv')\n",
    "test_dispers = pd.read_csv('../data_processing/test/test_entropy_std.csv')\n",
    "test_min = pd.read_csv('../data_processing/test/test_min.csv')\n",
    "test_max = pd.read_csv('../data_processing/test/test_max.csv')\n",
    "test_latest = test_latest.drop(test_latest.columns[0:12], axis=1)\n",
    "test_dispers = test_dispers.drop(test_dispers.columns[0:12], axis=1)\n",
    "test_min = test_min.drop(test_min.columns[0:12], axis=1)\n",
    "test_max = test_max.drop(test_max.columns[0:12], axis=1)\n",
    "test = pd.concat([test_median, test_latest, test_dispers, test_min, test_max], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate response and features\n",
    "X_train = train.drop(train.columns[0:13], axis=1)\n",
    "y_train = train[\"readmitted_within_30days\"]\n",
    "X_test = test.drop(test.columns[0:12], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: OrderedDict([('max_depth', 1135), ('min_samples_leaf', 2), ('min_samples_split', 2), ('n_estimators', 1614)])\n",
      "Best AUC: 0.8017\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees model (best performanc in kaggle submissions)\n",
    "# hyperparameter tuning - Bayesian optimization\n",
    "params = {\n",
    "    'n_estimators': Integer(1, 2000),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 20),\n",
    "    'max_depth': Integer(1, 2000),\n",
    "}\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(class_weight=\"balanced\", random_state=42)\n",
    "opt = BayesSearchCV(extra_trees, params, n_iter=50, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "best_params_extra_trees = opt.best_params_\n",
    "best_auc_extra_trees = opt.best_score_\n",
    "\n",
    "print(\"Best params:\", best_params_extra_trees)\n",
    "print(\"Best AUC: %.4f\" % best_auc_extra_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = opt.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]  # get the probabilities of the positive class\n",
    "df = pd.DataFrame({'id': test['id'], 'readmitted_within_30days': y_pred})\n",
    "df.to_csv('./prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
